# Gradiant Decent（梯度下降）
# 一、
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665561095088-66a0c46f-69e3-4cd7-b12a-79f847f3ae7e.png#averageHue=%23f6f5f5&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=634&id=ud3831078&originHeight=634&originWidth=884&originalType=binary&ratio=1&rotation=0&showTitle=false&size=273337&status=error&style=none&taskId=udf30e91b-d798-41f1-9717-05c73c10a63&title=&width=884)
> _η为学习率（learning rate即：lr)_

> ![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665574296986-a5f77b20-74e0-4bbe-8280-83878bf3563e.png#averageHue=%23eaeaea&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=48&id=u5e0f9961&originHeight=51&originWidth=73&originalType=binary&ratio=1&rotation=0&showTitle=false&size=3283&status=error&style=none&taskId=u5444b7f2-87f6-49bc-b83d-5074e824219&title=&width=68) Gradient，后面用g(_θ_)来代替



# 二、损失函数
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665575527310-9687a489-a671-4caf-8dfb-e737aa3a98d6.png#averageHue=%23fdfdfd&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=134&id=uc7d375e1&originHeight=182&originWidth=349&originalType=binary&ratio=1&rotation=0&showTitle=false&size=21203&status=error&style=shadow&taskId=u24ad2c15-bf69-4130-9a59-dd06c4757ab&title=&width=257)
L（_θ_）：损失函数，C:某一个损失值

# 三、Gradient（梯度）
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665578813990-0cadd56a-aacc-4ef8-80e7-bbe72d951fad.png#averageHue=%23e6e4dd&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=paste&height=85&id=u1ed8f9e0&originHeight=85&originWidth=458&originalType=binary&ratio=1&rotation=0&showTitle=false&size=26897&status=error&style=shadow&taskId=ube2908b7-825a-4c5a-a777-e3e13bf9bd7&title=&width=458)
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665576238825-1e89b926-d05b-4c36-9639-bd1589138333.png#averageHue=%23ecebe9&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=160&id=u6d186256&originHeight=160&originWidth=361&originalType=binary&ratio=1&rotation=0&showTitle=false&size=31742&status=error&style=shadow&taskId=u1a36db27-cf10-403e-8093-0861b63cb0a&title=&width=361)


## 一、![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665576415726-165f1b6d-59f4-48e7-87e1-7e5da3f754de.png#averageHue=%23e6e7e6&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=84&id=u1a37cf3d&originHeight=138&originWidth=76&originalType=binary&ratio=1&rotation=0&showTitle=false&size=10047&status=error&style=none&taskId=u0a6b73d1-6231-46e8-9545-deca44df530&title=&width=46)Forward pass(正向传播)
由上面的公式可以得到，z对w₁的偏微分为x₁，z对w₂的偏微分为x2，以此类推   

## 二、![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665576402810-228be85e-96e9-4e9e-bff7-cc0540d05c04.png#averageHue=%23eeeeec&clientId=u0d7867d0-8536-4&errorMessage=unknown%20error&from=paste&height=59&id=VkeLg&originHeight=117&originWidth=70&originalType=binary&ratio=1&rotation=0&showTitle=false&size=9984&status=error&style=none&taskId=ud40d4642-d71f-4195-bb3a-606920ac231&title=&width=35)Backwards pss(反向传播)
### 一、过程图
![过程图.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665584518459-6ea48b9c-a67a-4b37-9163-2e6c3394afb3.png#averageHue=%23f7f4f2&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=drop&id=u7510f1ce&originHeight=251&originWidth=750&originalType=binary&ratio=1&rotation=0&showTitle=false&size=94442&status=error&style=none&taskId=uc53826c8-34d3-4c99-a098-5f08f4ceb2c&title=)

### 二、第一个过程


![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665580053798-20180471-fe9c-493d-8019-ca94bc67f181.png#averageHue=%23f8f7f4&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=paste&height=376&id=u11815767&originHeight=376&originWidth=623&originalType=binary&ratio=1&rotation=0&showTitle=false&size=90409&status=error&style=shadow&taskId=u14156838-f6ef-434c-96b2-05017105333&title=&width=623)


> a为激活函数，b为偏差，x1、x2为特征值，w1、w2为权重，z=w₁x₁+w₂x₂+b

我们先将激活函数a设为sigmoid函数，sigmoid函数的公式为![sigmoid公式.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581099003-079d225c-d7ed-4dc6-bdb1-90f8b0536d0a.png#averageHue=%23f3f3f3&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=drop&id=uf229cef5&originHeight=50&originWidth=56&originalType=binary&ratio=1&rotation=0&showTitle=false&size=733&status=error&style=none&taskId=u53e77fb0-bbbe-479b-b17e-0cfe293c15a&title=)，图像为![sigmoid.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665580597616-844e3076-b62a-4058-b91d-ffa732e6d3d3.png#averageHue=%23fcfcfc&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=drop&height=312&id=u5de186f3&originHeight=596&originWidth=800&originalType=binary&ratio=1&rotation=0&showTitle=false&size=22396&status=error&style=none&taskId=u7455687e-fa12-4580-9160-b81c775f356&title=&width=419)
根据这张图我们可以知道，在![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665580286044-630e0aa5-aa02-4697-81c5-2ddf523ec450.png#averageHue=%23e6e6e6&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=paste&height=63&id=u0df6e6d8&originHeight=142&originWidth=279&originalType=binary&ratio=1&rotation=0&showTitle=false&size=21818&status=error&style=none&taskId=ubf677e5c-db15-4e40-b4c1-c927df5b4ce&title=&width=123)中，![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665580671973-2e62d788-29ee-4ab4-a746-e7678941c8c0.png#averageHue=%23e2e2e2&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=paste&height=60&id=u4e1dd37b&originHeight=60&originWidth=34&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2418&status=error&style=none&taskId=u9b22c9db-e161-4608-89e0-b766216fa25&title=&width=34)的结果为
_f_′(_x_)=_f_(_x_)(1−_f_(_x_))，图像为
![sigmoid求导.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665580748923-2eb1ef0f-10e1-4042-920b-9347a71fb5c3.png#averageHue=%23fcfcfc&clientId=ud276e104-c4a5-4&errorMessage=unknown%20error&from=drop&height=282&id=u27c2803f&originHeight=480&originWidth=640&originalType=binary&ratio=1&rotation=0&showTitle=false&size=26474&status=error&style=none&taskId=ucc27df20-7d74-438a-9dbc-b959d9d3c41&title=&width=376)

### 三、第二个过程
但![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581183109-c6611d22-3f95-4869-9cbb-d58a0dc576e3.png#averageHue=%23e2e2e2&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=62&id=ud26ee975&originHeight=62&originWidth=34&originalType=binary&ratio=1&rotation=0&showTitle=false&size=2426&status=error&style=none&taskId=u4b095993-0a66-4635-b293-92d66c7f9fc&title=&width=34)这一部分我们又应该怎么算呢？
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581211152-c0b77ff9-e163-409f-81fa-bd2e716735e0.png#averageHue=%23f6f3f1&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=250&id=u819f8059&originHeight=250&originWidth=428&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53057&status=error&style=none&taskId=u7e76aae8-d217-4e93-bd5b-570a5927e7e&title=&width=428)


第二个部分我们得到下面的公式
z'=aw₃+...
z''=aw₄+...

![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581458331-c68ce3d1-4ee7-4c50-9342-ad098bf80226.png#averageHue=%23e3e3e3&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=129&id=u6e5e1df4&originHeight=129&originWidth=489&originalType=binary&ratio=1&rotation=0&showTitle=false&size=40408&status=error&style=none&taskId=ufbe6a4f1-80ef-4fc0-a55e-b195bd8f6ca&title=&width=490)


同样，我们可以得出，![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581740585-43ee408f-f80b-4edb-81d9-f4f9383f426d.png#averageHue=%23dcdcdc&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=51&id=ub2f93d24&originHeight=122&originWidth=76&originalType=binary&ratio=1&rotation=0&showTitle=false&size=7832&status=error&style=none&taskId=uf63c993b-d7d6-4de2-a514-2597932cee1&title=&width=32)为w₃，![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665581770576-e9121f4e-3709-4fcb-896d-cbf594f240e0.png#averageHue=%23dadada&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=51&id=ua378a80d&originHeight=120&originWidth=78&originalType=binary&ratio=1&rotation=0&showTitle=false&size=9012&status=error&style=none&taskId=uf0bee357-03bd-480b-bda6-158e587d295&title=&width=33)为w₄
即：![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665582528752-f4fdfc59-304e-454a-8aa5-fb708c0dd1fa.png#averageHue=%23eeeeee&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=148&id=ue4b96d1f&originHeight=172&originWidth=629&originalType=binary&ratio=1&rotation=0&showTitle=false&size=39490&status=error&style=none&taskId=u6ffb9d10-920a-4d9c-9bbf-ad257292fba&title=&width=542)



现在，我们假设我们已经知道了![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665584945761-245a5dd6-a80b-4d44-863b-0296c680bde5.png#averageHue=%23d4d4d4&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=60&id=u3ab7361b&originHeight=117&originWidth=66&originalType=binary&ratio=1&rotation=0&showTitle=false&size=8008&status=error&style=none&taskId=ud09116b5-cfd8-434b-b9a2-da547ae2d21&title=&width=34)和![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665584955547-5cf8526c-3d1b-420c-bc54-cb5da193bd9c.png#averageHue=%23dddcdc&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=65&id=u1b2abb54&originHeight=134&originWidth=80&originalType=binary&ratio=1&rotation=0&showTitle=false&size=9355&status=error&style=none&taskId=u52e28ce6-7c0f-48e0-84a4-7b1777e0e98&title=&width=39)，那么，当我们反向传播的时候
![backward pass1.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665582337028-b859cec1-c1e2-4f91-ac5c-e0bbfd7393e2.png#averageHue=%23faf4f3&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=drop&id=u1bce2c28&originHeight=643&originWidth=644&originalType=binary&ratio=1&rotation=0&showTitle=false&size=126970&status=error&style=none&taskId=ud404818f-da4c-4391-a5ce-31bd6ccfe2b&title=)
按照前面的[过程图](https://www.yuque.com/remake-o6xfw/uw1exp/bfgnt5?inner=Z35fS)，如果在第二个过程后直接出结果y₁，y₂的话，
那么我们可以得出以下的结果
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665584720936-f295b07f-6f89-4880-b6f6-c64b2ebf068b.png#averageHue=%23fffffe&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=158&id=u0f430822&originHeight=158&originWidth=684&originalType=binary&ratio=1&rotation=0&showTitle=false&size=58688&status=error&style=none&taskId=u1e03aa05-9a35-4a98-9a3c-03111447995&title=&width=684)




有了上面的推到，我们看下面的这张图就比较容易理解了
![过程图2.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665585540341-f0de8053-bb6a-45fe-a0c7-280d704bda2e.png#averageHue=%23f8edeb&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=drop&id=u65393714&originHeight=566&originWidth=1204&originalType=binary&ratio=1&rotation=0&showTitle=false&size=297065&status=error&style=none&taskId=ud7ab38a4-748d-425a-a374-d358a3f4988&title=)



# 四、Decent（下降）
## 一、learning rate（学习率）
还记得刚刚第一张图吗，里面有个_η（learning rate）_
那它的作用是干么的呢？
![image.png](https://cdn.nlark.com/yuque/0/2022/png/33630082/1665586112337-80e9d026-c079-4752-beb3-021fa496b335.png#averageHue=%23f6efe9&clientId=u995b7dc3-69c9-4&errorMessage=unknown%20error&from=paste&height=740&id=ufcc950e6&originHeight=740&originWidth=1202&originalType=binary&ratio=1&rotation=0&showTitle=false&size=424934&status=error&style=none&taskId=u91f56585-994b-4baf-a211-5c96ec241be&title=&width=1202)
由上面这张图可知，在w⁰这个点上，w减小，loss增加，w增大loss减小
因为我们希望loss越小越好，所以我们要将w增大
如果我们把_η_设得大点，那个它参数更新的幅度会大一点
如果我们把_η_设得小点，那个它参数更新的幅度会小一点
